# -*- coding: utf-8 -*-
"""PrognosAI:AI-Driven Predictive Maintenance System Using Time-Series Sensor Data.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qHkze9gi7FjKEf25Bdc7g_JM8pjjC8u3
"""

import os

# Create data folder if not exists
os.makedirs("data", exist_ok=True)
os.makedirs("models", exist_ok=True)
os.makedirs("scalers", exist_ok=True)

print("Folders ready!")

from google.colab import files
uploaded = files.upload()

# Move uploaded files to /data folder
for fn in uploaded.keys():
    os.rename(fn, os.path.join("data", fn))

print("Files uploaded to /data folder!")

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import GRU, Dense, Dropout, BatchNormalization
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
import joblib
import math, glob

# Data integrity check - important for Milestone 1
print("Missing values per column:")
print(df.isna().sum())

def read_cmapss(file_path):
    col_names = ["unit","cycle",
                 "op_setting_1","op_setting_2","op_setting_3"] + \
                [f"s{i}" for i in range(1,22)]
    df = pd.read_csv(file_path, sep=r"\s+", header=None, names=col_names)
    return df

def add_rul(df):
    max_c = df.groupby("unit")["cycle"].max().reset_index()
    max_c.columns = ["unit","max_cycle"]
    df = df.merge(max_c,on="unit")
    df["RUL"] = df["max_cycle"] - df["cycle"]
    df.drop("max_cycle",axis=1,inplace=True)
    return df

train_file = "data/train_FD001.txt"
df = read_cmapss(train_file)
df = add_rul(df)

df.head()

CAP_RUL = 125
SEQ_LEN = 50

sensor_cols = [c for c in df.columns if c.startswith("s") or c.startswith("op_")]

df["RUL_cap"] = df["RUL"].clip(upper=CAP_RUL)

scaler_fd001 = StandardScaler()
scaler_fd001.fit(df[sensor_cols])
df[sensor_cols] = scaler_fd001.transform(df[sensor_cols])

def create_sequences(df):
    Xs, ys = [], []
    for u in sorted(df["unit"].unique()):
        temp = df[df["unit"] == u].sort_values("cycle")
        data, labels = temp[sensor_cols].values, temp["RUL_cap"].values
        if len(data) < SEQ_LEN: continue
        for i in range(len(data) - SEQ_LEN + 1):
            Xs.append(data[i:i+SEQ_LEN])
            ys.append(labels[i+SEQ_LEN-1])
    return np.array(Xs), np.array(ys)

X, y = create_sequences(df)
print("Sequence Data:", X.shape, y.shape)

X_train, X_val, y_train, y_val = train_test_split(
    X, y, test_size=0.15, random_state=42
)
print(X_train.shape, X_val.shape)

tf.keras.backend.clear_session()

model_fd001 = Sequential([
    GRU(128, input_shape=(SEQ_LEN, len(sensor_cols))),
    BatchNormalization(),
    Dropout(0.3),
    Dense(64, activation="relu"),
    Dense(1)
])

model_fd001.compile(optimizer="adam", loss="mse")

checkpoint_fd001 = ModelCheckpoint(
    "models/best_FD001.h5", monitor="val_loss", save_best_only=True
)

history = model_fd001.fit(
    X_train, y_train,
    epochs=30, batch_size=128,  # üî• changed epochs to 30
    validation_data=(X_val, y_val),
    callbacks=[checkpoint_fd001],
    verbose=2
)

joblib.dump(scaler_fd001, "scalers/scaler_FD001.joblib")

plt.figure(figsize=(8,4))
plt.plot(history.history["loss"], label="Train Loss")
plt.plot(history.history["val_loss"], label="Val Loss")
plt.xlabel("Epoch")
plt.ylabel("MSE")
plt.title("Training & Validation Loss Curve - FD001")
plt.legend()
plt.grid(True)
plt.show()

import math
y_vp = model_fd001.predict(X_val).ravel()
rmse_fd001 = math.sqrt(mean_squared_error(y_val,y_vp))
print("FD001 Validation RMSE:", rmse_fd001)

plt.plot(history.history["loss"], label="train")
plt.plot(history.history["val_loss"], label="val")
plt.legend()
plt.title("FD001 - Loss Curve")
plt.show()

df_test = read_cmapss("data/test_FD001.txt")
df_test[sensor_cols] = scaler_fd001.transform(df_test[sensor_cols])

# Last window per engine
X_test = []
for u in sorted(df_test["unit"].unique()):
    temp = df_test[df_test["unit"]==u].sort_values("cycle")[sensor_cols].values
    if len(temp) >= SEQ_LEN:
        X_test.append(temp[-SEQ_LEN:])
    else:
        pad = np.repeat(temp[0:1], SEQ_LEN - len(temp), axis=0)
        X_test.append(np.vstack([pad,temp]))

X_test = np.array(X_test)

y_true = pd.read_csv("data/RUL_FD001.txt", header=None)[0].clip(upper=CAP_RUL).values
y_pred = model_fd001.predict(X_test).ravel()

rmse_test_fd001 = math.sqrt(mean_squared_error(y_true,y_pred))
print("FD001 Test RMSE:", rmse_test_fd001)

plt.scatter(y_true,y_pred,alpha=0.6)
plt.plot([0,125],[0,125],"k--")
plt.xlabel("True")
plt.ylabel("Predicted")
plt.title("FD001 - Predicted vs True RUL")
plt.show()

plt.figure(figsize=(10,4))
plt.plot(y_val[:200], label="Actual RUL")
plt.plot(y_val_pred[:200], label="Predicted RUL")
plt.title("FD001 Validation: Predicted vs Actual RUL (first 200 samples)")
plt.xlabel("Sample Index")
plt.ylabel("RUL")
plt.legend()
plt.grid(True)
plt.show()

# ---- FD001 Test Set Evaluation ----
test_file = os.path.join(DATA_DIR, "test_FD001.txt")
rul_file  = os.path.join(DATA_DIR, "RUL_FD001.txt")

df_test_raw = read_cmapss(test_file)
df_test_scaled = df_test_raw.copy()
df_test_scaled[sensor_cols] = scaler_fd001.transform(df_test_raw[sensor_cols].values)

# Last SEQ_LEN cycles per engine
X_test = []
test_units = sorted(df_test_scaled["unit"].unique())
for u in test_units:
    tmp = df_test_scaled[df_test_scaled["unit"] == u]
    arr = tmp[sensor_cols].values

    if arr.shape[0] >= SEQ_LEN:
        X_test.append(arr[-SEQ_LEN:])
    else:
        pad_n = SEQ_LEN - arr.shape[0]
        pad = np.vstack([arr[0]] * pad_n)
        X_test.append(np.vstack([pad, arr]))

X_test = np.array(X_test)

# True RUL
y_test_true = pd.read_csv(rul_file, header=None).values.ravel()

# Predictions
y_test_pred = model_fd001.predict(X_test).ravel()

# RMSE
test_rmse = math.sqrt(mean_squared_error(y_test_true, y_test_pred))
print(f"Test RMSE (FD001): {test_rmse:.4f}")

# Plot true vs predicted
plt.figure(figsize=(8,4))
plt.scatter(y_test_true, y_test_pred, alpha=0.6)
plt.plot([0, max(y_test_true)], [0, max(y_test_true)], 'k--')
plt.xlabel("True RUL")
plt.ylabel("Predicted RUL")
plt.title("FD001: True vs Predicted RUL (Test Set)")
plt.grid(True)
plt.show()

# ---- FD001 Error Analysis ----
errors = y_test_pred - y_test_true

# Histogram of errors
plt.figure(figsize=(8,4))
plt.hist(errors, bins=20, alpha=0.75)
plt.axvline(0, color='k', linestyle='--')
plt.title("FD001: Error Distribution (Predicted - True RUL)")
plt.xlabel("Prediction Error")
plt.ylabel("Frequency")
plt.grid(True)
plt.show()

# Error vs True RUL
plt.figure(figsize=(8,4))
plt.scatter(y_test_true, errors, alpha=0.6)
plt.axhline(0, color='k', linestyle='--')
plt.xlabel("True RUL")
plt.ylabel("Prediction Error")
plt.title("FD001: Error vs True RUL")
plt.grid(True)
plt.show()

print("Mean Error:", np.mean(errors))
print("Std Dev of Error:", np.std(errors))

# Ordered Actual vs Predicted RUL for FD001
sorted_idx = np.argsort(y_test_true)  # sort by actual RUL
y_true_sorted = y_test_true[sorted_idx]
y_pred_sorted = y_test_pred[sorted_idx]

plt.figure(figsize=(12,6))
plt.plot(y_true_sorted, label="Actual RUL", linewidth=3, color='blue')
plt.plot(y_pred_sorted, label="Predicted RUL", linewidth=2, color='orange')
plt.title("FD001: Ordered Actual vs Predicted RUL (Test Set)")
plt.xlabel("Sorted Engine Index")
plt.ylabel("RUL")
plt.grid(True)
plt.legend()
plt.show()

"""FD002"""

import os
os.makedirs("data", exist_ok=True)
print("Data folder ready!")

from google.colab import files
uploaded = files.upload()

import os

for fname in uploaded.keys():
    os.rename(fname, os.path.join("data", fname))

print("FD002 files moved into /data folder")
print("Files now present:", os.listdir("data"))

import tensorflow as tf
tf.keras.backend.clear_session()

# Load FD002 Training Data
train_fd2 = read_cmapss("data/train_FD002.txt")

# Add RUL column
def add_rul(df):
    max_cycle = df.groupby("unit")["cycle"].max().reset_index()
    max_cycle.columns = ["unit", "max_cycle"]
    df = df.merge(max_cycle, on="unit")
    df["RUL"] = df["max_cycle"] - df["cycle"]
    return df.drop(columns=["max_cycle"])

train_fd2 = add_rul(train_fd2)
print("FD002 Training data shape:", train_fd2.shape)

# Sensor + op setting columns
sensor_cols = [c for c in train_fd2.columns if c.startswith("s") or c.startswith("op_setting")]

# Cap RUL to reduce imbalance
train_fd2["RUL_capped"] = train_fd2["RUL"].clip(upper=125)

# Scale features
from sklearn.preprocessing import StandardScaler
scaler_fd2 = StandardScaler()
train_fd2[sensor_cols] = scaler_fd2.fit_transform(train_fd2[sensor_cols])

def create_sequences(df, seq_len=50):
    X, y = [], []
    for unit in df["unit"].unique():
        unit_data = df[df["unit"] == unit].sort_values("cycle")
        features = unit_data[sensor_cols].values
        rul_vals = unit_data["RUL_capped"].values

        for i in range(len(features) - seq_len + 1):
            X.append(features[i:i+seq_len])
            y.append(rul_vals[i+seq_len-1])

    return np.array(X), np.array(y)

SEQ_LEN = 50
X_fd2, y_fd2 = create_sequences(train_fd2, SEQ_LEN)

print("FD002 Sequence set shape:", X_fd2.shape, y_fd2.shape)

from sklearn.model_selection import train_test_split

X_train_fd2, X_val_fd2, y_train_fd2, y_val_fd2 = train_test_split(
    X_fd2, y_fd2, test_size=0.15, random_state=42, shuffle=True
)

print(X_train_fd2.shape, X_val_fd2.shape)

model_fd2 = Sequential([
    GRU(128, input_shape=(SEQ_LEN, len(sensor_cols))),
    BatchNormalization(),
    Dropout(0.3),
    Dense(64, activation="relu"),
    Dense(1)
])

model_fd2.compile(optimizer="adam", loss="mse")

checkpoint_fd2 = ModelCheckpoint("best_FD002.h5", monitor="val_loss",
                                 save_best_only=True)

history_fd2 = model_fd2.fit(
    X_train_fd2, y_train_fd2,
    validation_data=(X_val_fd2, y_val_fd2),
    epochs=30, batch_size=128,
    callbacks=[checkpoint_fd2],
    verbose=2
)

joblib.dump(scaler_fd2, "scaler_FD002.joblib")

plt.plot(history_fd2.history["loss"], label="Train Loss")
plt.plot(history_fd2.history["val_loss"], label="Val Loss")
plt.title("FD002 Training vs Validation Loss")
plt.xlabel("Epochs")
plt.ylabel("MSE Loss")
plt.legend()
plt.grid(True)
plt.show()

y_val_pred_fd2 = model_fd2.predict(X_val_fd2).ravel()
rmse_val_fd2 = math.sqrt(mean_squared_error(y_val_fd2, y_val_pred_fd2))
print("FD002 Validation RMSE:", rmse_val_fd2)

plt.figure(figsize=(12,5))
plt.plot(y_test_true[:100], label="Actual RUL", linewidth=2)
plt.plot(y_test_pred[:100], label="Predicted RUL", linewidth=2)
plt.title("FD002: Actual vs Predicted RUL (First 100 Test Units)")
plt.xlabel("Engine Index")
plt.ylabel("RUL")
plt.legend()
plt.grid(True)
plt.show()

# Load Test data & True RUL for FD002
df_test_raw_2 = read_cmapss("data/test_FD002.txt")
true_rul_fd2 = pd.read_csv("data/RUL_FD002.txt", sep=r"\s+", header=None).values.ravel()
CAP_RUL = 125
true_rul_fd2 = np.clip(true_rul_fd2, None, CAP_RUL)

# Scale test data using saved scaler
df_test_raw_2[sensor_cols] = scaler_fd2.transform(df_test_raw_2[sensor_cols])

# Create sequences for each test unit
X_test_fd2 = []
units_fd2 = sorted(df_test_raw_2["unit"].unique())

for unit in units_fd2:
    temp_df = df_test_raw_2[df_test_raw_2["unit"] == unit].sort_values("cycle")
    arr = temp_df[sensor_cols].values

    if len(arr) >= SEQ_LEN:
        X_test_fd2.append(arr[-SEQ_LEN:])
    else:
        # Pad start with first row if shorter
        pad_len = SEQ_LEN - len(arr)
        pad = np.repeat(arr[0:1], pad_len, axis=0)
        X_test_fd2.append(np.vstack([pad, arr]))

X_test_fd2 = np.array(X_test_fd2)

# Predictions
pred_rul_fd2 = model_fd2.predict(X_test_fd2).ravel()

# RMSE on Test set
rmse_test_fd2 = math.sqrt(mean_squared_error(true_rul_fd2, pred_rul_fd2))
print("\nüìå FD002 Test RMSE:", rmse_test_fd2)

# Error calculations
errors_fd2 = pred_rul_fd2 - true_rul_fd2

# 1Ô∏è‚É£ True vs Predicted RUL Scatter
plt.figure(figsize=(8,5))
plt.scatter(true_rul_fd2, pred_rul_fd2, alpha=0.7)
plt.plot([0, 125], [0, 125], 'k--')
plt.xlabel("True RUL")
plt.ylabel("Predicted RUL")
plt.title("FD002: True vs Predicted RUL (Test Set)")
plt.grid(True)
plt.show()

# 2Ô∏è‚É£ Error Distribution (Histogram)
plt.figure(figsize=(8,5))
plt.hist(errors_fd2, bins=25, alpha=0.75)
plt.axvline(0, linestyle="--", color="black")
plt.xlabel("Prediction Error")
plt.ylabel("Frequency")
plt.title("FD002: Error Distribution")
plt.grid(True)
plt.show()

# 3Ô∏è‚É£ Error vs True RUL scatter
plt.figure(figsize=(8,5))
plt.scatter(true_rul_fd2, errors_fd2, alpha=0.7)
plt.axhline(0, linestyle="--", color="black")
plt.xlabel("True RUL")
plt.ylabel("Prediction Error")
plt.title("FD002: Error vs True RUL")
plt.grid(True)
plt.show()

print("Mean Error:", np.mean(errors_fd2))
print("Std Dev Error:", np.std(errors_fd2))

sorted_idx = np.argsort(y_test_true)

plt.figure(figsize=(12,5))
plt.plot(np.array(y_test_true)[sorted_idx], 'b-', label="Actual RUL")
plt.plot(np.array(y_test_pred)[sorted_idx], 'r-', label="Predicted RUL")
plt.title("FD002: Ordered Actual vs Predicted RUL")
plt.xlabel("Sorted Engine Index")
plt.ylabel("RUL")
plt.legend()
plt.grid(True)
plt.show()

"""FD003"""

from google.colab import files

uploaded = files.upload()

for fn in uploaded.keys():
    os.rename(fn, os.path.join("data", fn))

print("Files successfully moved to data/:")
print(os.listdir("data"))

import os, math
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import GRU, Dense, Dropout, BatchNormalization
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
import joblib

tf.keras.backend.clear_session()

DATA_DIR = "./data"
print("Files in data:", os.listdir(DATA_DIR))

def read_cmapss(file_path):
    col_names = ["unit", "cycle",
                 "op_setting_1", "op_setting_2", "op_setting_3"] \
                + [f"s{i}" for i in range(1, 22)]
    df = pd.read_csv(file_path, sep=r"\s+", header=None, names=col_names)
    return df

# Load FD003 training data
train_fd3 = read_cmapss(os.path.join(DATA_DIR, "train_FD003.txt"))
print("FD003 train shape:", train_fd3.shape)

# Add RUL = max_cycle - current_cycle
max_cycle_fd3 = train_fd3.groupby("unit")["cycle"].max().reset_index()
max_cycle_fd3.columns = ["unit", "max_cycle"]

train_fd3 = train_fd3.merge(max_cycle_fd3, on="unit", how="left")
train_fd3["RUL"] = train_fd3["max_cycle"] - train_fd3["cycle"]
train_fd3.drop("max_cycle", axis=1, inplace=True)

train_fd3.head()

CAP_RUL = 125
SEQ_LEN = 50

sensor_cols_fd3 = [c for c in train_fd3.columns
                   if c.startswith("s") or c.startswith("op_setting")]

# Cap RUL to reduce effect of very large lifetimes
train_fd3["RUL_capped"] = train_fd3["RUL"].clip(upper=CAP_RUL)

# Scale sensor + op_setting features
scaler_fd3 = StandardScaler()
train_fd3[sensor_cols_fd3] = scaler_fd3.fit_transform(train_fd3[sensor_cols_fd3])

print("Number of sensors/op settings (FD003):", len(sensor_cols_fd3))
print("Any missing values?\n", train_fd3.isna().sum().sum(), "(0 means none)")

def create_sequences_fd3(df, seq_len, sensor_cols):
    X, y = [], []
    for u in df["unit"].unique():
        tmp = df[df["unit"] == u].sort_values("cycle")
        data = tmp[sensor_cols].values
        labels = tmp["RUL_capped"].values

        if len(data) < seq_len:
            continue

        for i in range(len(data) - seq_len + 1):
            X.append(data[i:i+seq_len])
            y.append(labels[i+seq_len-1])
    return np.array(X), np.array(y)

X_fd3, y_fd3 = create_sequences_fd3(train_fd3, SEQ_LEN, sensor_cols_fd3)
print("FD003 sequence data:", X_fd3.shape, y_fd3.shape)

X_train_fd3, X_val_fd3, y_train_fd3, y_val_fd3 = train_test_split(
    X_fd3, y_fd3, test_size=0.15, random_state=42, shuffle=True
)

print("FD003 train:", X_train_fd3.shape,
      "val:", X_val_fd3.shape)

tf.keras.backend.clear_session()

model_fd3 = Sequential([
    # First GRU layer (returns sequences to feed next GRU)
    GRU(128, return_sequences=True,
        input_shape=(SEQ_LEN, len(sensor_cols_fd3))),
    Dropout(0.3),

    # Second GRU layer (compress full sequence into one vector)
    GRU(64, return_sequences=False),
    BatchNormalization(),
    Dropout(0.3),

    # Dense layers for regression
    Dense(64, activation="relu"),
    Dense(1)   # linear output for RUL
])

model_fd3.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),
                  loss="mse")

model_fd3.summary()

callbacks_fd3 = [
    EarlyStopping(monitor="val_loss", patience=8,
                  restore_best_weights=True, verbose=1),
    ModelCheckpoint("best_FD003.h5", monitor="val_loss",
                    save_best_only=True, verbose=1)
]

history_fd3 = model_fd3.fit(
    X_train_fd3, y_train_fd3,
    validation_data=(X_val_fd3, y_val_fd3),
    epochs=40,
    batch_size=128,
    callbacks=callbacks_fd3,
    verbose=2
)

joblib.dump(scaler_fd3, "scaler_FD003.joblib")

plt.figure(figsize=(8,4))
plt.plot(history_fd3.history["loss"], label="Train Loss")
plt.plot(history_fd3.history["val_loss"], label="Val Loss")
plt.xlabel("Epoch")
plt.ylabel("MSE Loss")
plt.title("FD003: Training vs Validation Loss (Stacked GRU)")
plt.legend()
plt.grid(True)
plt.show()

y_val_pred_fd3 = model_fd3.predict(X_val_fd3).ravel()
rmse_val_fd3 = math.sqrt(mean_squared_error(y_val_fd3, y_val_pred_fd3))
print("FD003 Validation RMSE:", rmse_val_fd3)

# optional: first 200 validation samples
plt.figure(figsize=(10,4))
plt.plot(y_val_fd3[:200], label="Actual RUL")
plt.plot(y_val_pred_fd3[:200], label="Predicted RUL")
plt.title("FD003 Validation: Predicted vs Actual RUL (first 200 samples)")
plt.xlabel("Sample index")
plt.ylabel("RUL")
plt.legend()
plt.grid(True)
plt.show()

# Load and scale test data
test_fd3 = read_cmapss(os.path.join(DATA_DIR, "test_FD003.txt"))
test_fd3[sensor_cols_fd3] = scaler_fd3.transform(test_fd3[sensor_cols_fd3])

X_test_fd3 = []
units_fd3 = sorted(test_fd3["unit"].unique())

for u in units_fd3:
    tmp = test_fd3[test_fd3["unit"] == u].sort_values("cycle")
    arr = tmp[sensor_cols_fd3].values

    if len(arr) >= SEQ_LEN:
        X_test_fd3.append(arr[-SEQ_LEN:])
    else:
        pad_len = SEQ_LEN - len(arr)
        pad = np.repeat(arr[0:1], pad_len, axis=0)
        X_test_fd3.append(np.vstack([pad, arr]))

X_test_fd3 = np.array(X_test_fd3)

# True RULs
y_test_true_fd3 = pd.read_csv(
    os.path.join(DATA_DIR, "RUL_FD003.txt"),
    sep=r"\s+", header=None
).values.ravel()
y_test_true_fd3 = np.clip(y_test_true_fd3, None, CAP_RUL)

# Predictions
y_test_pred_fd3 = model_fd3.predict(X_test_fd3).ravel()

rmse_test_fd3 = math.sqrt(mean_squared_error(y_test_true_fd3, y_test_pred_fd3))
print("üìå FD003 Test RMSE:", rmse_test_fd3)

plt.figure(figsize=(8,5))
plt.scatter(y_test_true_fd3, y_test_pred_fd3, alpha=0.7)
plt.plot([0, CAP_RUL], [0, CAP_RUL], "k--")
plt.xlabel("True RUL")
plt.ylabel("Predicted RUL")
plt.title("FD003: True vs Predicted RUL (Test Set)")
plt.grid(True)
plt.show()

errors_fd3 = y_test_pred_fd3 - y_test_true_fd3

plt.figure(figsize=(8,5))
plt.hist(errors_fd3, bins=25, alpha=0.8)
plt.axvline(0, color='k', linestyle='--')
plt.xlabel("Prediction Error (Pred - True)")
plt.ylabel("Frequency")
plt.title("FD003: Error Distribution")
plt.grid(True)
plt.show()

plt.figure(figsize=(8,5))
plt.scatter(y_test_true_fd3, errors_fd3, alpha=0.7)
plt.axhline(0, color='k', linestyle='--')
plt.xlabel("True RUL")
plt.ylabel("Prediction Error")
plt.title("FD003: Error vs True RUL")
plt.grid(True)
plt.show()

print("Mean Error FD003:", np.mean(errors_fd3))
print("Std Dev Error FD003:", np.std(errors_fd3))

sorted_idx_fd3 = np.argsort(y_test_true_fd3)
true_sorted_fd3 = y_test_true_fd3[sorted_idx_fd3]
pred_sorted_fd3 = y_test_pred_fd3[sorted_idx_fd3]

plt.figure(figsize=(12,5))
plt.plot(true_sorted_fd3, label="Actual RUL", linewidth=3, color="blue")
plt.plot(pred_sorted_fd3, label="Predicted RUL", linewidth=2, color="orange")
plt.xlabel("Sorted Engine Index")
plt.ylabel("RUL")
plt.title("FD003: Ordered Actual vs Predicted RUL (Test Set)")
plt.grid(True)
plt.legend()
plt.show()

"""FD004

"""

from google.colab import files
uploaded = files.upload()

import os
os.makedirs("data", exist_ok=True)

for fname in uploaded.keys():
    os.replace(fname, os.path.join("data", fname))

print("Files now present:", os.listdir("data"))

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import GRU, Dense, Dropout, BatchNormalization
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
import joblib
import math

def read_cmapss(fp):
    col_names = ["unit", "cycle",
                 "op1", "op2", "op3"] + [f"s{i}" for i in range(1,22)]
    return pd.read_csv(fp, sep=r"\s+", header=None, names=col_names)

train_fd4 = read_cmapss("data/train_FD004.txt")

max_cycle = train_fd4.groupby("unit")["cycle"].max()
train_fd4 = train_fd4.merge(max_cycle, on="unit", suffixes=("","_max"))
train_fd4["RUL"] = train_fd4["cycle_max"] - train_fd4["cycle"]
train_fd4.drop(columns=["cycle_max"], inplace=True)

train_fd4.head()

sensor_cols = [c for c in train_fd4.columns if c.startswith("s") or c.startswith("op")]
train_fd4["RUL"] = train_fd4["RUL"].clip(upper=125)

scaler_fd4 = StandardScaler()
train_fd4[sensor_cols] = scaler_fd4.fit_transform(train_fd4[sensor_cols])
joblib.dump(scaler_fd4, "scaler_FD004.joblib")

SEQ_LEN = 50

def create_sequences(df):
    X, y = [], []
    for u in df["unit"].unique():
        tmp = df[df["unit"] == u].sort_values("cycle")
        values = tmp[sensor_cols].values
        rul = tmp["RUL"].values
        for i in range(len(tmp)-SEQ_LEN):
            X.append(values[i:i+SEQ_LEN])
            y.append(rul[i+SEQ_LEN-1])
    return np.array(X), np.array(y)

X_fd4, y_fd4 = create_sequences(train_fd4)

print(X_fd4.shape, y_fd4.shape)

X_train, X_val, y_train, y_val = train_test_split(
    X_fd4, y_fd4, test_size=0.15, shuffle=True, random_state=42)

print(X_train.shape, X_val.shape)

def build_stacked_gru():
    model = Sequential([
        GRU(128, return_sequences=True, input_shape=(SEQ_LEN, len(sensor_cols))),
        Dropout(0.3),
        GRU(64, return_sequences=False),
        BatchNormalization(),
        Dense(32, activation='relu'),
        Dense(1)
    ])
    model.compile(optimizer=tf.keras.optimizers.Adam(1e-3), loss='mse')
    return model

model_fd4 = build_stacked_gru()
model_fd4.summary()

callbacks = [
    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),
    ModelCheckpoint("best_FD004.h5", save_best_only=True, monitor='val_loss')
]

history = model_fd4.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=30,
    batch_size=128,
    callbacks=callbacks,
    verbose=2
)

y_val_pred = model_fd4.predict(X_val).ravel()
rmse_val_fd4 = math.sqrt(mean_squared_error(y_val, y_val_pred))
print(f"FD004 Validation RMSE: {rmse_val_fd4:.4f}")

plt.figure(figsize=(10,4))
plt.plot(y_val[:200], label="Actual RUL")
plt.plot(y_val_pred[:200], label="Predicted RUL")
plt.legend(); plt.title("FD004 Validation: First 200 Samples")
plt.show()

df_test = read_cmapss("data/test_FD004.txt")
df_test[sensor_cols] = scaler_fd4.transform(df_test[sensor_cols])

X_test = []
for u in df_test["unit"].unique():
    tmp = df_test[df_test["unit"] == u].sort_values("cycle")
    arr = tmp[sensor_cols].values
    if len(arr) >= SEQ_LEN:
        X_test.append(arr[-SEQ_LEN:])
    else:
        pad = np.repeat(arr[0:1], SEQ_LEN-len(arr), axis=0)
        X_test.append(np.vstack((pad, arr)))

X_test = np.array(X_test)
y_test_true = pd.read_csv("data/RUL_FD004.txt", header=None).values.ravel().clip(125)
y_test_pred = model_fd4.predict(X_test).ravel()

rmse_test_fd4 = math.sqrt(mean_squared_error(y_test_true, y_test_pred))
print(f"üìå FD004 Test RMSE: {rmse_test_fd4:.4f}")

plt.figure(figsize=(8,6))
plt.scatter(y_test_true, y_test_pred)
plt.plot([0,125],[0,125],'k--')
plt.xlabel("True RUL"); plt.ylabel("Predicted RUL")
plt.title("FD004: True vs Predicted RUL (Test)")
plt.show()

errors = y_test_pred - y_test_true
plt.hist(errors, bins=30)
plt.axvline(x=0, linestyle="--", color="black")
plt.title("FD004 Error Distribution")
plt.show()

plt.scatter(y_test_true, errors)
plt.axhline(y=0, linestyle="--", color="black")
plt.title("FD004 Error vs True RUL")
plt.show()

print("Mean Error:", np.mean(errors))
print("Std Dev Error:", np.std(errors))

# FD004 Ordered Actual vs Predicted RUL Plot

# Sort results by actual RUL for better visualization
sort_idx_fd4 = np.argsort(y_test_true)

plt.figure(figsize=(12,5))
plt.plot(np.array(y_test_true)[sort_idx_fd4], label="Actual RUL", linewidth=2)
plt.plot(np.array(y_test_pred)[sort_idx_fd4], label="Predicted RUL", linewidth=2)

plt.title("FD004: Ordered Actual vs Predicted RUL")
plt.xlabel("Sample Index (sorted by Actual RUL)")
plt.ylabel("RUL")
plt.legend()
plt.grid(True)
plt.show()